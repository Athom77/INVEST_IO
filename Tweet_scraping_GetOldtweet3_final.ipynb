{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet_scraping_GetOldtweet3_final.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM2rYX5kdsbc0WIqnOo+EtF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Athom77/INVEST_IO/blob/master/Tweet_scraping_GetOldtweet3_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYHNQEhOyx7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libraries\n",
        "\n",
        "!pip install GetOldTweets3\n",
        "import GetOldTweets3 as got\n",
        "import importlib\n",
        "from textblob import TextBlob\n",
        "import datetime as dt\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "#import google translate API to pass the tweet text and translate it in english.\n",
        "!pip install googletrans\n",
        "import googletrans\n",
        "from googletrans import Translator\n",
        "\n",
        "\n",
        "# re = python module for regular expression\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "#consumer_key = 'Vzk6O5t967f1n4iz9iQcsQwhf'\n",
        "#consumer_secret = 'Q8sncdY1j85mwNitOqb5Spcg6U6uuZ0E2KNHHZEYF2J4DdCyVi'\n",
        "#access_token = '164224789-mFmU5YhessCNvubNojgfL605tbU0vh0NOna3HdQU'\n",
        "#access_secret = 'Ic5LNOH2QqxziSq4eTQdJvbXo3noTcQDUzCKXgFcdPzpC'\n",
        "\n",
        "consumer_key = 'A4y6ir5ElROyMEiW2WeTQlOXZ'\n",
        "consumer_secret = 'XYh3oKBJPfNTpnafqDUd4sYb2qe9yHLHHSbzGEInQ4iIlwVBtz'\n",
        "access_token = '381610804-WSQku72JaKFK7IgeI4fVhRBdpf0bP85WR9Dd3DNM'\n",
        "access_secret = 'o131rMJs1O7jFjHbvrKuRmNOPRuQCmkSsKh8Fuu9oxIu6'\n",
        "\n",
        "# Importing GetOldTweets3\n",
        "\n",
        "def get_tweets(username, top_only, start_date, end_date, max_tweets):\n",
        "   \n",
        "    # specifying tweet search criteria \n",
        "    tweetCriteria = got.manager.TweetCriteria().setUsername(username)\\\n",
        "                          .setTopTweets(top_only)\\\n",
        "                          .setSince(start_date)\\\n",
        "                          .setUntil(end_date)\\\n",
        "                          .setMaxTweets(max_tweets)\n",
        "    \n",
        "    # scraping tweets based on criteria\n",
        "    tweet = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "    \n",
        "    # creating list of tweets with the tweet attributes \n",
        "    # specified in the list comprehension\n",
        "    text_tweets = [[tw.date,\n",
        "                tw.id,\n",
        "                tw.username,\n",
        "                tw.permalink,\n",
        "                tw.text,\n",
        "                tw.hashtags,\n",
        "                tw.favorites,\n",
        "                tw.geo,\n",
        "                tw.retweets,\n",
        "                tw.mentions] for tw in tweet]\n",
        "    \n",
        "    # creating dataframe, assigning column names to list of\n",
        "    # tweets corresponding to tweet attributes\n",
        "    news_df = pd.DataFrame(text_tweets, \n",
        "                            columns = ['created_at', 'id', 'user', 'url', 'text', 'hashtags', 'favorite_count', 'location', 'retweet', 'user_mentions'])\n",
        "    \n",
        "    return news_df\n",
        "\n",
        "#2 SENTIMENT ANALYSIS\n",
        "# # # # TWITTER STREAM LISTENER - Analyzer # # # #\n",
        "# we can use TextBlob for tweet sentiment analysis and determine the polarity of tweet, from -3 to 3;\n",
        "# -3 = negative, 0 = neutral, 3 = positive\n",
        " \n",
        "class TweetAnalyzer():\n",
        "    \"\"\"\n",
        "    Functionality for analyzing and categorizing content from tweets.\n",
        "    \"\"\"\n",
        "    # claen_tweet using the re module to clean tweets text \n",
        "    def clean_tweet(self, text):\n",
        "        return str(' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", text).split()))\n",
        "    def translator(self, text):\n",
        "        translator = Translator()\n",
        "        translated_tweet = str(translator.translate(text))\n",
        "    def analyze_sentiment(self, text):\n",
        "        analysis = TextBlob(self.clean_tweet(text))\n",
        "        \n",
        "        if analysis.sentiment.polarity > 0:\n",
        "            return 3\n",
        "        elif analysis.sentiment.polarity == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            return -3\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ePL3kWzIe_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining news sources I want to include\n",
        "news_sources = \"$AMZN\"\n",
        "\n",
        "# news_sources = ['$AAPL', '$AMZN', '$MSFT', '$GOOGL', '$FB', '$BABA', '$0700', '$BRK', '$V', '$WMT', '$JNJ', '$TSM', '$TSLA', '$PG']\n",
        "# getting tweets from the defined new sources, \n",
        "# only including top tweets, \n",
        "# looking at the past week with the end_date not inclusive,\n",
        "# and specifying that we want a max number of tweets = 100.\n",
        "# also sorting the tweets by date, descending.\n",
        "\n",
        "initial_date = \"2020-01-01\"\n",
        "final_date = \"2020-09-01\"\n",
        "max_tweet = 10  #per keyword\n",
        "\n",
        "news_df = get_tweets(news_sources, top_only = True, start_date = initial_date, end_date = final_date, max_tweets = max_tweet).sort_values('created_at', ascending=False)\n",
        "\n",
        "# getting the tweet full text \n",
        "pd.set_option(\"display.max_colwidth\", -1)\n",
        "\n",
        "# adding the new items 'date' and 'ticker'\n",
        "ticker = str(news_sources)\n",
        "\n",
        "#news_df[\"date\"] = news_df[\"created_at\"].dt.strftime(\"%Y-%m-%d\")\n",
        "news_df[\"ticker\"] = f'{news_sources.replace(\"$\", \"\")}'\n",
        "\n",
        "## call the class TweetAnalyzer before fill in the column 'sentiment'\n",
        "tweet_analyzer = TweetAnalyzer()\n",
        "\n",
        "# ETL on tweets: cleaning, translate, sentiment analysis:\n",
        "\n",
        "translator = Translator()\n",
        "news_df['cleaned_text'] = np.array([tweet_analyzer.clean_tweet(text) for text in news_df['text']])\n",
        "news_df['translated_text'] = np.array([translator.translate(text) for text in news_df['cleaned_text']])\n",
        "\n",
        "#text language detection\n",
        "\n",
        "news_df['dect_lan'] = np.array([translator.detect(text) for text in news_df['cleaned_text']])\n",
        "news_df['dect_lan'] = str(news_df['dect_lan'])[19:21].upper()\n",
        "\n",
        "#sentiment analysis\n",
        "\n",
        "polarity = lambda x: TextBlob(x).sentiment.polarity\n",
        "subjectivity = lambda x: TextBlob(x).sentiment.subjectivity\n",
        "\n",
        "news_df['polarity'] = news_df['text'].astype(str).apply(polarity)\n",
        "news_df['subjectivity'] = news_df['text'].astype(str).apply(subjectivity)\n",
        "\n",
        "tweet_analyzer = TweetAnalyzer()\n",
        "\n",
        "news_df['sentiment_analysis'] = np.array([tweet_analyzer.analyze_sentiment(text) for text in news_df['text']])\n",
        "\n",
        "#salvataggio file csv con stringa del TS convertito in data\n",
        "\n",
        "news_df = news_df[['date', 'ticker', 'user', 'url', 'created_at', 'id', 'text', 'hashtags', 'dect_lan', 'favorite_count', 'location', 'retweet', 'user_mentions', 'polarity', 'subjectivity', 'sentiment_analysis']]\n",
        "#news_df = news_df[['date', 'ticker', 'user', 'link', 'created_at', 'id', 'text', 'hashtags', 'favorite_count', 'location', 'retweet', 'user_mentions', 'polarity', 'subjectivity', 'sentiment_analysis']]\n",
        "\n",
        "news_df.to_csv(f'tweet_{initial_date.replace(\"-\", \"\")}' + \"_\" + f'{final_date.replace(\"-\", \"\")}' + \"_\" +  f'{news_sources.replace(\"$\" , \"\")}' + \".csv\", index= False)\n",
        "#files.download(f'tweet_{initial_date.replace(\"-\", \"\")}' + \"_\" + f'{final_date.replace(\"-\", \"\")}' + \"_\" +  f'{news_sources.replace(\"$\" , \"\")}' + \".csv\")\n",
        "news_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccyTMoLpVvNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting\n",
        "\n",
        "news_df['sentiment_analysis'].value_counts().plot(kind = 'bar')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ3AxiWpcmoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#Create the wordcloud with the text created above\n",
        "wordcloud = WordCloud().generate(text)\n",
        "\n",
        "#Plot the text with the lines below\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zYLzgy7lDni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_news['sentiment_analysis']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}